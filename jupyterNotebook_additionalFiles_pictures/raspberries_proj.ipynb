{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from activations import *\n",
    "from helpers1 import *\n",
    "from helpers2 import *\n",
    "from helpers_conv import *\n",
    "from helpers_fc import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = [\n",
    "\"pics/Zdrava_malina/\",\n",
    "\"pics/Antrakoza_maline_Anthracnose/\",\n",
    "\"pics/Bakteriozni_rak_Crown_Gall_and_Cane_Gall/\",\n",
    "\"pics/Siva_trulez_Cane_botrytis_Botrytis_cinerea_Gray_Mold_Powdery/\",\n",
    "\"pics/Bakteriozna_plamenjaca_Erwinia_amylovora/\",\n",
    "\"pics/Malinina_musica_galica_Lasioptera_rubi/\",\n",
    "\"pics/Narandzasta_rdja_Orange_Rust_Phragmidium/\",\n",
    "\"pics/Plamenjača_korena_maline_Fitoftora_Fragariae_var_rubi_Phytophthora/\",\n",
    "\"pics/Ljubicasta_pegavost_Sušenje_izdanaka_maline_Didymella_applanata_Spur_blight_and_Cane_blight/\",\n",
    "\"pics/virus/Raspberry_bushy_dwarf_RBDV/\",\n",
    "\"pics/virus/Tackasti_list_Leaf_spot/\",\n",
    "\"pics/virus/uzrok_vasi/Mozaik_Raspberry_mosaic/\",\n",
    "\"pics/virus/uzrok_vasi/Kovrdzanje_listova_Raspberry_leaf_curl/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pixel values\n",
    "num_of_dirs = len(dir_names)\n",
    "pixels, m = readAllPixels(num_of_dirs,dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset 'x' - store all values from 'pixels' in one vector 'x'\n",
    "# Create dataset 'y' - \n",
    "# Images: 200x200x3, Data: m x dim(image)\n",
    "\n",
    "x = np.zeros((m, pixels[0][0].shape[0],pixels[0][0].shape[1], pixels[0][0].shape[2]))\n",
    "y = np.zeros((m, num_of_dirs))\n",
    "c1, c2 = 0, 0\n",
    "\n",
    "for i in range(num_of_dirs):\n",
    "    for j in range(len(pixels[i])):\n",
    "        x[c1] = pixels[i][j]\n",
    "        y[c1][c2] = 1\n",
    "        c1 = c1 + 1 \n",
    "    c2 = c2 + 1\n",
    "\n",
    "print(\"Number of all examples: \" + str(x.shape[0]) + \" images\")\n",
    "print(\"Dimension of dataset x: \" + str(x.shape))\n",
    "print(\"Dimension of dataset y: \" + str(y.shape))\n",
    "print()\n",
    "print(\"x, y data type is: \"+ str(type(x[0][0][0][0]))+ \", \" + str(type(y[0][0])) )\n",
    "print()\n",
    "print(\"y values for pictures comming from first sub-directory:\\n \" + str(y[len(pixels[0])-1]))\n",
    "print(\"y values for pictures comming from second sub-directory:\\n \" + str(y[len(pixels[0])]))\n",
    "print(\"y values for pictures comming from third sub-directory:\\n \" + str(y[len(pixels[0])+len(pixels[1])]))\n",
    "print(\"...\")\n",
    "print(\"y values for pictures comming from last sub-directory:\\n \" + str(y[m-1]))\n",
    "    \n",
    "# Free memory immediately (I)\n",
    "pixels = None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "# Free memory immediately (II)\n",
    "x, y = None, None\n",
    "\n",
    "# Standardize data\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "m_train = x_train.shape[0]\n",
    "m_test = x_test.shape[0]\n",
    "num_px = x_train.shape[1]\n",
    "depth = x_train.shape[3]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/width of each square image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", \" + str(depth) + \")\\n\")\n",
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape) + \"\\n\")\n",
    "print (\"Number of all examples/images: m = \" + str(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # MODEL # # # # # # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims_conv, channels, nc, layers_dims_fc,\n",
    "          learning_rate_init = 0.0007, mini_batch_size = 64, beta1 = 0.9, beta2 = 0.999,  \n",
    "          epsilon = 1e-8, num_epochs = 100, print_cost = True):\n",
    "    costs = []                       # to keep track of the cost\n",
    "    bcost = []\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    \n",
    "    hparameters1 = {\"pad\" : 2, \"stride\": 3}\n",
    "    hparameters2 = {\"stride\" : 2, \"f\": 2}\n",
    "    hparameters3 = {\"pad\" : 1, \"stride\": 3}\n",
    "    hparameters4 = {\"stride\" : 2, \"f\": 2}   \n",
    "\n",
    "    # Initialize parameters CONV\n",
    "    parameters_conv = initialize_parameters_rand_CONV(layers_dims_conv,channels,nc)\n",
    "    # Initialize parameters FC\n",
    "    parameters_fc = initialize_parameters_he_FC(layers_dims_fc)\n",
    "    # Gather parameters in python dict\n",
    "    parameters_all = solve_all(parameters_conv, parameters_fc)\n",
    "    L = len(parameters_fc) // 2                  # number of layers in the neural network\n",
    "    # Initialize the optimizer\n",
    "    v, s = initialize_adam(parameters_all)\n",
    "    learning_param1 = learning_rate_init / 40\n",
    "    train_num = X.shape[0]\n",
    "    learning_param2 = int( train_num / mini_batch_size )\n",
    "    for i in range(num_epochs):\n",
    "            learning_rate = learning_rate_init * (1/(1+learning_param1*(i*learning_param2)))\n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "            real = i + 1\n",
    "            if print_cost:\n",
    "                print (\"Running Epoch %i...\" %(real))\n",
    "                print (\"Learning rate = \" + str(learning_rate))\n",
    "\n",
    "            for minibatch in minibatches:         \n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Get parameters for CONV network, parameters_conv\n",
    "                parameters_conv = solve_conv(parameters_all, layers_dims_conv, channels, nc)\n",
    "                # Forward propagation CONV                             \n",
    "                P2, cache_pool2, cache_pool1, cache_conv1, cache_conv2, c1, c2 = Convolutional_Forward(\n",
    "                    minibatch_X, parameters_conv, hparameters1, hparameters2, hparameters3, hparameters4)\n",
    "\n",
    "                # Create 2D input for FC nerwork, FC1\n",
    "                FC1 = P2.reshape(P2.shape[0], -1).T\n",
    "                \n",
    "                # Get parameters for FC network, parameters_fc\n",
    "                parameters_fc = solve_fc(parameters_all, layers_dims_conv)\n",
    "                # Forward propagation FC\n",
    "                AL, cache_fc = L_model_forward(FC1, parameters_fc)\n",
    "                \n",
    "                # Compute cost\n",
    "                cost = cross_entropy_loss(AL, minibatch_Y.T)                \n",
    "                if print_cost:\n",
    "                    bcost.append(cost)\n",
    "\n",
    "                # Backward propagation FC\n",
    "                grads_fc = L_model_backward(AL, minibatch_Y.T, cache_fc, minibatch_X.T)    \n",
    "                \n",
    "                # Backward propagation CONV, I\n",
    "                dP2 = pool_backward(P2, cache_pool2, mode = \"max\")\n",
    "                dA2 = relu_backward(dP2, c2)\n",
    "                dZ2, dW2, db2 = conv_backward(dA2, cache_conv2)\n",
    "                # Backward propagation CONV, II\n",
    "                dP1 = pool_backward(dZ2, cache_pool1, mode = \"max\")\n",
    "                dA1 = relu_backward(dP1, c1)\n",
    "                dZ1, dW1, db1 = conv_backward(dA1, cache_conv1)\n",
    "                \n",
    "                # Gather data\n",
    "                parameters_all = solve_all(parameters_conv, parameters_fc)\n",
    "                grads_all = solve_all_grads(grads_fc, dA1, dW1, db1, dA2, dW2, db2 )\n",
    "                \n",
    "                # Update parameters with Adam optimizer\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters_all, v, s = update_parameters_with_adam(parameters_all, grads_all, v, s, t, \n",
    "                                                                   learning_rate, beta1, beta2,  epsilon)\n",
    "                \n",
    "            # Print the cost after every epoch & save\n",
    "            if print_cost:\n",
    "                print (\"Cost after epoch %i: %f\" %(real, cost))\n",
    "                costs.append(cost)\n",
    "                print(\"\\n\\n\\n\")\n",
    "\n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    # plot the bcost\n",
    "    plt.plot(bcost)\n",
    "    plt.ylabel('batch cost')\n",
    "    plt.xlabel('batch epochs')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "        \n",
    "    return parameters_all, cost, bcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims_conv = [5, 3]                    # In first conv layer dim(filter)=(fxfxc)=5x5xc1 \n",
    "                                             # where c1 is a number of channels for the first filter\n",
    "                                             # In second  conv layer dim(filter)=(fxfxc)=3x3xc2 \n",
    "                                             # where c2 is a number of channels for the second filter\n",
    "        \n",
    "channels = [3, 4]                            # c1 = 3, c2 = 4\n",
    "nc = [4, 8]                                  # Number of filters in first conv layer = 4, second = 8\n",
    "layers_dims_fc = [200, 447, 774, 1094, 631, 315, 181, 127, 73, 36, 20, num_of_dirs]\n",
    "\n",
    "\n",
    "# train 2-layer convolutional & 3-layer fully-connected model\n",
    "parameters, cost, bcost = model(x_train, y_train, layers_dims_conv, channels, nc, layers_dims_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "print (\"On the train set:\")\n",
    "pred_train = predict(x_train, y_train, parameters, layers_dims_conv, channels, nc)\n",
    "print (\"On the test set:\")\n",
    "pred_test = predict(x_test, y_test, parameters, layers_dims_conv, channels, nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
